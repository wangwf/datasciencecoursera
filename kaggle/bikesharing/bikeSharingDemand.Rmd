---
title: "(Kaggle) Bike Sharing Demand -- Forecast use of a city bikeshare system"
output: html_document
---
## Bike Sharing Demand

Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.

The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.
## Data Fields

datetime - hourly date + timestamp  
season -  1 = spring, 2 = summer, 3 = fall, 4 = winter 
holiday - whether the day is considered a holiday
workingday - whether the day is neither a weekend nor holiday
weather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy 
2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist 
3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds 
4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog 
temp - temperature in Celsius
atemp - "feels like" temperature in Celsius
humidity - relative humidity
windspeed - wind speed
casual - number of non-registered user rentals initiated
registered - number of registered user rentals initiated
count - number of total rentals

## Load data
```{r, echo=FALSE}
getwd()
setwd("/home/wenfeng/code/datasciencecoursera/kaggle/bikesharing")
```

```{r loaddata, echo=TRUE}
trainSet <- read.csv("train.csv")
testSet <- read.csv("test.csv")
dim(trainSet)
dim(testSet)
names(trainSet)
names(testSet)
```

```{r datasummary}
str(trainSet)
summary(trainSet)
```



## Explore data
```{r }
par(mfrow = c(3,3))
hist(trainSet$season)
hist(trainSet$holiday)
hist(trainSet$workingday)
hist(trainSet$weather)
plot(trainSet$temp,trainSet$atemp)
hist(trainSet$humidity)
hist(trainSet$windspeed)
par(mfrow=c(1,1))
```

SeasonDependecen
```{r seasonDependence}
library(ggplot2)
library(gridExtra)
qplot(x=count, data=trainSet, fill=as.factor(season))
p1 <- qplot(x=count, data=trainSet, fill=as.factor(season)) + scale_x_sqrt()
p2 <- qplot(x=casual, data=trainSet, fill=as.factor(season))+scale_x_sqrt()
p3 <- qplot(x=registered, data=trainSet, fill=as.factor(season))+scale_x_sqrt()

grid.arrange(p1,p2,p3)
```


```{r holidayDependence}
qplot(x=count, data=trainSet, fill=as.factor(holiday))
p1 <- qplot(x=count, data=trainSet, fill=as.factor(holiday)) + scale_x_sqrt()
p2 <- qplot(x=casual, data=trainSet, fill=as.factor(holiday))+scale_x_sqrt()
p3 <- qplot(x=registered, data=trainSet, fill=as.factor(holiday))+scale_x_sqrt()

grid.arrange(p1,p2,p3)
```


```{r weatherDependence}
qplot(x=count, data=trainSet, fill=as.factor(weather))
p1 <- qplot(x=count, data=trainSet, fill=as.factor(weather)) + scale_x_sqrt()
p2 <- qplot(x=casual, data=trainSet, fill=as.factor(weather))+scale_x_sqrt()
p3 <- qplot(x=registered, data=trainSet, fill=as.factor(weather))+scale_x_sqrt()
grid.arrange(p1,p2,p3)
```


```{r tempDependence}
ggplot(aes(x=temp, y=count), data=trainSet)+geom_jitter()+geom_smooth(method="lm", color="blue")
cor(trainSet$count, trainSet$temp)
cor(trainSet$casual, trainSet$temp)
cor(trainSet$registered, trainSet$temp)
```

```{r corTemp}
cor.test(trainSet$temp, trainSet$atemp)
```


```{r humidityDependence}
ggplot(aes(x=humidity, y=count), data=trainSet)+geom_jitter()+geom_smooth(method="lm", color="blue")
cor(trainSet$count, trainSet$humidity)
 cor(trainSet$casual, trainSet$humidity)
cor(trainSet$registered, trainSet$humidity)
```


```{r windspeedDependence}
ggplot(aes(x=windspeed, y=count), data=trainSet)+geom_jitter()+geom_smooth(method="lm", color="blue")
cor(trainSet$count, trainSet$windspeed)
cor(trainSet$casual, trainSet$windspeed)
cor(trainSet$registered, trainSet$windspeed)
```

Correlation Matrix
```{r}
round(cor(trainSet[,-1]))
```
 
 Converting datetime from factor to datetime variable, then split on date and time.

```{r}
trainSet<- transform(trainSet, season=factor(season), holiday=factor(holiday), workingday=factor(workingday), weather=factor(weather))
trainSet$date <- strftime(trainSet$datetime, format="%Y-%m-%d")
trainSet$hour <- strftime(trainSet$datetime, format="%H")

testSet<- transform(testSet, season=factor(season), holiday=factor(holiday), workingday=factor(workingday), weather=factor(weather))
testSet$date <- strftime(testSet$datetime, format="%Y-%m-%d")
testSet$hour <- strftime(testSet$datetime, format="%H")

```

```{r}
library(caret)
ind <- createDataPartition(y=trainSet$count, p=0.7, list=F)
mytrainSet <- trainSet[ind,]
mytestSet <- trainSet[-ind,]

```

```{r, echo=FALSE}
outputFile<-function(p){
    output <- subset(testSet, select='datetime')
    output$count<-p
    outname <- paste0('results/out_', format(Sys.time(), "%y%m%d_%H%M%S"),".csv")
    write.csv(output,outname, quote=FALSE, row.names=FALSE)
    }

BikeEva <- function(data, pred){
    pred[pred<0]<-0
    return(sqrt(1/length(data) * sum((log(pred + 1) - log(data+1))^2)))
}
```
## Train models
```{r model1}
lm1 <-lm(count ~temp+humidity+hour, data=trainSet)
p<-round(predict(lm1, newdata=trainSet))
plot(trainSet$count, p)
BikeEva(trainSet$count,p)
```


```{r}
library(rpart)
ff <- formula(count ~ season+ holiday+ workingday+ weather+ temp+ atemp+  humidity +windspeed + hour)
modelRpart<- rpart(ff, data=trainSet)
p<-round(predict(modelRpart, newdata=trainSet))
plot(trainSet$count, p)
BikeEva(trainSet$count,p)

ptest<- round(predict(modelRpart, newdata=testSet))
outputFile(ptest)
```

```{r}
library(randomForest)
modelRF <- randomForest(ff, data=trainSet)
rfPred <- round(predict(modelRF, newdata=trainSet))
importance(modeRF)
plot(trainSet$count, rfPred)
BikeEva(trainSet$count,rfPred)

ptest<- round(predict(modelRF, newdata=testSet))
outputFile(ptest)
```


```{r}
libary(caret)
#lm2 <-lm(count ~ ., data=trainSet, method="lm") #
lm2 <- train(count ~temp+humidity+hour, data=trainSet, method="lm")
p<-round(predict(lm2, newdata=trainSet))
BikeEva(trainSet$count,p)

#ptest<- round(predict(lm1, newdata=testSet))
#outputFile(ptest)
```

```{r}
modelgbm <- train(count~., data=trainSet, method="gbm")
p<-round(predict(modelgbm, newdata=trainSet))
BikeEva(trainSet$count,p)
```

```{r}
modelgbm2 <- train(count~.+ I(atemp^2) + I(hour^2), data=trainSet, method="gbm")
p<-round(predict(modelgbm2, newdata=trainSet))
BikeEva(trainSet$count,p)
```

Boosting alo
```{r}
modelgbm <- train(count~.+ I(atemp^2) + I(hour^2), data=trainSet, method="cubist")
p<-round(predict(modelgbm, newdata=trainSet))
BikeEva(trainSet$count,p)
```


```{r}
library(randomForest)
f1 <- formula(log10(casual+1) ~ season+ holiday+ workingday+ weather+ temp+ atemp+  humidity +windspeed + hour)
f2 <- formula(log10(registered+1) ~ season+ holiday+ workingday+ weather+ temp+ atemp+  humidity +windspeed + hour)
rfmodel1 <- randomForest(f1, data=trainSet)
importance(rfmodel1)
rfmodel2 <- randomForest(f2, data=trainSet)
importance(rfmodel2)
p1 <- predict(rfmodel1, newdata=trainSet)
p2 <- predict(rfmodel2, newdata=trainSet)
p12 <- round(10^p1 + 10^p2-2)
BikeEva(trainSet$count, p12)

pt1 <- predict(rfmodel1, newdata=testSet)
pt2 <- predict(rfmodel2, newdata=testSet)
pt12 <- round(10^pt1 + 10^pt2)
outputFile(pt12)

```
submitted .


```{r}
library(RWeka)
mod1 <- M5P(f1, data=trainSet)
mod2 <- M5P(f2, data=trainSet)
p1 <- predict(mode1, newdata=trainSet)
p2 <- predict(model2, newdata=trainSet)
p12 <- round(10^p1 + 10^p2 -2)
BikeEva(trainSet$count, p12)
```
