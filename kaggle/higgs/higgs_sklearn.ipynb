{
 "metadata": {
  "name": "",
  "signature": "sha256:f3d163efc10ad840e95215a73670b3493433105ad1742017658340ad255f5af9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " \n",
      "# Load training data\n",
      "print 'Loading training data.'\n",
      "data_train = np.loadtxt( 'training.csv', delimiter=',', skiprows=1, converters={32: lambda x:int(x=='s'.encode('utf-8')) } )\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pick a random seed for reproducible results. Choose wisely!\n",
      "np.random.seed(42)\n",
      "# Random number for training/validation splitting\n",
      "r =np.random.rand(data_train.shape[0])\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Put Y(truth), X(data), W(weight), and I(index) into their own arrays\n",
      "print 'Assigning data to numpy arrays.'\n",
      "# First 90% are training\n",
      "Y_train = data_train[:,32][r<0.9]\n",
      "X_train = data_train[:,2:31][r<0.9]\n",
      "W_train = data_train[:,31][r<0.9]\n",
      "# Lirst 10% are validation\n",
      "Y_valid = data_train[:,32][r>=0.9]\n",
      "X_valid = data_train[:,2:31][r>=0.9]\n",
      "W_valid = data_train[:,31][r>=0.9]\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Assigning data to numpy arrays.\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tuningGBC():\n",
      "    tuned_parameters =[{'n_estimators':[50],'max_depth':[10,12,15],'min_samples_leaf':[150,200,250],'max_features':[10, 15, 20]}]\n",
      "    scores = ['precision', 'recall']\n",
      "    from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "    for score in scores:\n",
      "        clf =GridSearchCV(GBC(verbose=1), tuned_parameters, scoring=score)\n",
      "        clf.fit(X_train, Y_train)\n",
      "\n",
      "        print(\"Best parameters set found on development set:\")\n",
      "        print()\n",
      "        print(clf.best_estimator_)\n",
      "        print()\n",
      "        print(\"Grid scores on development set:\")\n",
      "        print()\n",
      "        for params, mean_score, scores in clf.grid_scores_:\n",
      "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "              % (mean_score, scores.std() / 2, params))\n",
      "        print()\n",
      "\n",
      "        \n",
      "tuningGBC()\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      Iter       Train Loss   Remaining Time \n",
        "         1           1.2117            1.72m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         2           1.1520            1.67m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         3           1.0987            1.63m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         4           1.0545            1.58m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         5           1.0152            1.56m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         6           0.9823            1.53m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         7           0.9535            1.49m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         8           0.9270            1.45m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         9           0.9038            1.41m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        10           0.8844            1.38m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        20           0.7668            1.03m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        30           0.7154           41.58s"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tuningSVM():\n",
      "    # Set the parameters by cross-validation\n",
      "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-4],\n",
      "                         'C': [1]},\n",
      "                        {'kernel': ['linear'], 'C': [1]}]\n",
      "\n",
      "    scores = ['precision', 'recall']\n",
      "    from sklearn.svm import SVC\n",
      "\n",
      "    for score in scores:\n",
      "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
      "        print()\n",
      "\n",
      "        clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5, scoring=score)\n",
      "        clf.fit(X_train, Y_train)\n",
      "\n",
      "        print(\"Best parameters set found on development set:\")\n",
      "        print()\n",
      "        print(clf.best_estimator_)\n",
      "        print()\n",
      "        print(\"Grid scores on development set:\")\n",
      "        print()\n",
      "        for params, mean_score, scores in clf.grid_scores_:\n",
      "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
      "                  % (mean_score, scores.std() / 2, params))\n",
      "        print()\n",
      "\n",
      "#tuningSVM()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train the GradientBoostingClassifier using our good features\n",
      "print 'Training classifier (this may take some time!)'\n",
      "#gbc = GBC(n_estimators=50, max_depth=12,min_samples_leaf=200,max_features=10,verbose=1)\n",
      "#gbc = GBC(n_estimators=50,learning_rate=0.1, max_depth=12, max_features=10, min_samples_leaf=250,verbose=1)\n",
      "gbc = GBC(learning_rate=0.1, loss='deviance', max_depth=15, max_features=10, min_samples_leaf=150,verbose=1)\n",
      "gbc.fit(X_train,Y_train) \n",
      "\n",
      "#from sklearn.ensemble import RandomForestClassifier\n",
      "#gbf = RandomForestClassifier(n_estimators=10)\n",
      "#gbf = gbf.fit(X_train, Y_train)  #clf\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training classifier (this may take some time!)\n",
        "      Iter       Train Loss   Remaining Time \n",
        "         1           1.2035            7.65m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         2           1.1349            7.37m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         3           1.0775            7.30m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         4           1.0298            7.16m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         5           0.9908            7.09m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         6           0.9547            7.01m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         7           0.9232            6.98m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         8           0.8950            6.89m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "         9           0.8717            6.79m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        10           0.8490            6.72m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        20           0.7199            6.01m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        30           0.6609            5.31m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        40           0.6242            4.60m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        50           0.6004            3.91m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        60           0.5843            3.20m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        70           0.5717            2.46m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        80           0.5616            1.67m"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "        90           0.5513           50.89s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       100           0.5449            0.00s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 140,
       "text": [
        "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
        "              max_depth=15, max_features=10, min_samples_leaf=150,\n",
        "              min_samples_split=2, n_estimators=100, random_state=None,\n",
        "              subsample=1.0, verbose=1)"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the probaility output from the trained method, using the 10% for testing\n",
      "prob_predict_train = gbc.predict_proba(X_train)[:,1]\n",
      "prob_predict_valid = gbc.predict_proba(X_valid)[:,1]\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Experience shows me that choosing the top 15% as signal gives a good AMS score.\n",
      "# This can be optimized though!\n",
      "pcut = np.percentile(prob_predict_train,85)\n",
      " \n",
      "# This are the final signal and background predictions\n",
      "Yhat_train = prob_predict_train > pcut \n",
      "Yhat_valid = prob_predict_valid > pcut\n",
      " \n",
      "# To calculate the AMS data, first get the true positives and true negatives\n",
      "# Scale the weights according to the r cutoff.\n",
      "TruePositive_train = W_train*(Y_train==1.0)*(1.0/0.9)\n",
      "TrueNegative_train = W_train*(Y_train==0.0)*(1.0/0.9)\n",
      "TruePositive_valid = W_valid*(Y_valid==1.0)*(1.0/0.1)\n",
      "TrueNegative_valid = W_valid*(Y_valid==0.0)*(1.0/0.1)\n",
      " \n",
      "# s and b for the training \n",
      "s_train = sum ( TruePositive_train*(Yhat_train==1.0) )\n",
      "b_train = sum ( TrueNegative_train*(Yhat_train==1.0) )\n",
      "s_valid = sum ( TruePositive_valid*(Yhat_valid==1.0) )\n",
      "b_valid = sum ( TrueNegative_valid*(Yhat_valid==1.0) )\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Now calculate the AMS scores\n",
      "print 'Calculating AMS score for a probability cutoff pcut=',pcut\n",
      "def AMSScore(s,b): return  math.sqrt (2.*( (s + b + 10.)*math.log(1.+s/(b+10.))-s))\n",
      "print '   - AMS based on 90% training   sample:',AMSScore(s_train,b_train)\n",
      "print '   - AMS based on 10% validation sample:',AMSScore(s_valid,b_valid)\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Calculating AMS score for a probability cutoff pcut= 0.842683254063\n",
        "   - AMS based on 90% training   sample: 6.27546013468\n",
        "   - AMS based on 10% validation sample: 3.67097883583\n"
       ]
      }
     ],
     "prompt_number": 143
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Now we load the testing data, storing the data (X) and index (I)\n",
      "print 'Loading testing data'\n",
      "data_test = np.loadtxt( 'test.csv', delimiter=',', skiprows=1 )\n",
      "X_test = data_test[:,2:31]\n",
      "I_test = list(data_test[:,0])\n",
      " \n",
      "# Get a vector of the probability predictions which will be used for the ranking\n",
      "print 'Building predictions'\n",
      "Predictions_test = gbc.predict_proba(X_test)[:,1]\n",
      "# Assign labels based the best pcut\n",
      "Label_test = list(Predictions_test>pcut)\n",
      "Predictions_test =list(Predictions_test)\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading testing data\n",
        "Building predictions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Now we get the CSV data, using the probability prediction in place of the ranking\n",
      "print 'Organizing the prediction results'\n",
      "resultlist = []\n",
      "for x in range(len(I_test)):\n",
      "    resultlist.append([int(I_test[x]), Predictions_test[x], 's'*(Label_test[x]==1.0)+'b'*(Label_test[x]==0.0)])\n",
      " \n",
      "# Sort the result list by the probability prediction\n",
      "resultlist = sorted(resultlist, key=lambda a_entry: a_entry[1]) \n",
      " \n",
      "# Loop over result list and replace probability prediction with integer ranking\n",
      "for y in range(len(resultlist)):\n",
      "    resultlist[y][1]=y+1\n",
      " \n",
      "# Re-sort the result list according to the index\n",
      "resultlist = sorted(resultlist, key=lambda a_entry: a_entry[0])\n",
      " \n",
      "# Write the result list data to a csv file\n",
      "print 'Writing a final csv file Kaggle_higgs_prediction_output.csv'\n",
      "fcsv = open('Kaggle_higgs_prediction_output.csv','w')\n",
      "fcsv.write('EventId,RankOrder,Class\\n')\n",
      "for line in resultlist:\n",
      "    theline = str(line[0])+','+str(line[1])+','+line[2]+'\\n'\n",
      "    fcsv.write(theline) \n",
      "fcsv.close()\n",
      " \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Organizing the prediction results\n",
        "Writing a final csv file Kaggle_higgs_prediction_output.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    }
   ],
   "metadata": {}
  }
 ]
}