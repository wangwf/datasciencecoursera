{
 "metadata": {
  "name": "",
  "signature": "sha256:64d6d3677208e94152354d1a1c1d7a5ad984efe79429a6c3e8ada527ee7956cf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "train_dir =\"train/\"\n",
      "\n",
      "all_classes = np.array(os.listdir(train_dir))\n",
      "n_classes = len(all_classes)\n",
      "print \"\\n Number of classes: \", n_classes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " Number of classes:  121\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#count the number of images in each class\n",
      "nimg_per_class = np.zeros(n_classes, dtype='int')\n",
      "for i,cls in enumerate(all_classes):\n",
      "    nimg_per_class[i] = len(os.listdir(train_dir +\"/\"+cls))\n",
      "\n",
      "# sort\n",
      "\n",
      "indx = np.argsort(-nimg_per_class)\n",
      "all_classes = all_classes[indx]\n",
      "nimg_per_class = nimg_per_class[indx]\n",
      "\n",
      "\n",
      "# \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(nimg_per_class)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "array([1979, 1934, 1189, 1172,  914,  899,  889,  815,  708,  703,  696,\n",
        "        694,  681,  678,  625,  536,  532,  519,  511,  500,  483,  439,\n",
        "        425,  417,  412,  394,  393,  385,  372,  363,  352,  336,  317,\n",
        "        287,  286,  274,  247,  242,  236,  229,  212,  201,  190,  179,\n",
        "        178,  175,  174,  173,  170,  158,  153,  150,  141,  136,  135,\n",
        "        132,  131,  128,  127,  123,  114,  113,  113,  108,  108,  106,\n",
        "         96,   96,   92,   88,   87,   85,   80,   77,   76,   75,   73,\n",
        "         71,   65,   64,   63,   61,   57,   56,   55,   54,   53,   52,\n",
        "         49,   49,   49,   43,   42,   38,   38,   38,   36,   35,   31,\n",
        "         30,   30,   29,   29,   27,   24,   24,   24,   23,   21,   19,\n",
        "         16,   16,   14,   14,   14,   13,   13,   12,   10,   10,    9])"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import matplotlib.pyplot as plt\n",
      "plt.hist(nimg_per_class, bins=np.linspace(1, 2000, 200))\n",
      "plt.xlabel(\"number of images\")\n",
      "plt.ylabel(\"number of classes\")\n",
      "#plt.savefig(\"images_per_class.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<matplotlib.text.Text at 0x5501f90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x+1/oSXNzdEzAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x51a8810>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print some stats\n",
      "#===========================================\n",
      "print\n",
      "print \"ten classes with fewest images ...\"\n",
      "for i in range(10):\n",
      "    print nimg_per_class[-(i+1)], all_classes[-(i+1)]\n",
      "\n",
      "print\n",
      "print \"ten classes with most images ...\"\n",
      "for i in range(10):\n",
      "    print nimg_per_class[i], all_classes[i]\n",
      "\n",
      "\n",
      "# write out classes in reverse order\n",
      "#===========================================\n",
      "with open(\"class_list.txt\", \"w\") as f:\n",
      "    for i in range(n_classes):\n",
      "        f.write(\"{} {}\\n\".format(all_classes[i], nimg_per_class[i]))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "ten classes with fewest images ...\n",
        "9 hydromedusae_haliscera_small_sideview\n",
        "10 heteropod\n",
        "10 fish_larvae_deep_body\n",
        "12 hydromedusae_other\n",
        "13 acantharia_protist_big_center\n",
        "13 pteropod_theco_dev_seq\n",
        "14 ephyra\n",
        "14 hydromedusae_typeE\n",
        "14 invertebrate_larvae_other_A\n",
        "16 appendicularian_fritillaridae\n",
        "\n",
        "ten classes with most images ...\n",
        "1979 trichodesmium_puff\n",
        "1934 chaetognath_other\n",
        "1189 copepod_cyclopoid_oithona_eggs\n",
        "1172 protist_other\n",
        "914 detritus_other\n",
        "899 copepod_cyclopoid_oithona\n",
        "889 acantharia_protist\n",
        "815 chaetognath_non_sagitta\n",
        "708 trichodesmium_bowtie\n",
        "703 hydromedusae_solmaris\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import numpy as np\n",
      "\n",
      "from skimage.io import imread\n",
      "from skimage import morphology\n",
      "from skimage import measure\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier as RF\n",
      "from sklearn import cross_validation\n",
      "from sklearn.cross_validation import StratifiedKFold as KFold\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib import cm\n",
      "\n",
      "#import const \n",
      "\n",
      "\n",
      "\n",
      "plt.ion() # turns on interactive plotting "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# set the path to the training images\n",
      "TRAIN_BASE=\"competition_data/train\"\n",
      "\n",
      "# get the class names from the directory names\n",
      "CLASS_NAMES = os.listdir(TRAIN_BASE)\n",
      "\n",
      "# this just adds the prefix path to the class names\n",
      "DIRECTORY_NAMES = [os.path.join(TRAIN_BASE, cn) for cn in CLASS_NAMES]\n",
      "\n",
      "# a list of the path to all training images\n",
      "TRAIN_IMAGE_PATHS = []\n",
      "for dn in DIRECTORY_NAMES:\n",
      "    for fn in os.listdir(dn):\n",
      "        image_path = os.path.join(dn,fn)\n",
      "        TRAIN_IMAGE_PATHS.append(image_path)\n",
      "\n",
      "# number of training images\n",
      "NTRAIN = len(TRAIN_IMAGE_PATHS)\n",
      "\n",
      "# set a default training image\n",
      "DEFAULT_IMAGE_FILE = os.path.join(TRAIN_BASE, \"acantharia_protist/101574.jpg\")\n",
      "\n",
      "#const =const()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "#  rescale_train_images\n",
      "#\n",
      "import subprocess\n",
      "\n",
      "\n",
      "\n",
      "npx = 25 #int(sys.argv[1])\n",
      "output_dir = \"competition_data/train_{0}x{0}\".format(npx)\n",
      "if not os.path.isdir(output_dir):\n",
      "    os.mkdir(output_dir)\n",
      "\n",
      "print 'output_dir=', output_dir\n",
      "print 'npx=', npx\n",
      "\n",
      "convert = \"convert -resize {0}x{0}! \".format(npx)\n",
      "print 'convert=', convert\n",
      "\n",
      "classes = os.listdir(TRAIN_BASE)\n",
      "print 'classes=', classes\n",
      "\n",
      "for c in classes:\n",
      "    class_dir = os.path.join(output_dir,c)\n",
      "    if not os.path.isdir(class_dir):\n",
      "        os.mkdir(class_dir)\n",
      "    imgs = os.listdir(os.path.join(TRAIN_BASE,c))\n",
      "    for img in imgs:\n",
      "        cmnd = os.path.join(convert + TRAIN_BASE, c, img)\n",
      "        cmnd += os.path.join(' ' + output_dir, c, img)\n",
      "        print cmnd\n",
      "        subprocess.call(cmnd.split())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_image(fname=const.DEFAULT_IMAGE_FILE, verbose=False):\n",
      "    \"\"\" Read an image and return a numpy uint8 array of values \"\"\" \n",
      "    if verbose: print 'reading ', fname\n",
      "    # note as_grey=True returns an array of uint8 between 0 and 255\n",
      "    im = imread(fname, as_grey=True)\n",
      "    return im\n",
      "\n",
      "def get_all_train_image_sizes():\n",
      "    im_sizes = np.zeros((const.NTRAIN,2))\n",
      "    for i,fn in enumerate(const.TRAIN_IMAGE_PATHS):\n",
      "        im = read_image(fn)\n",
      "        im_sizes[i,:] = im.shape\n",
      "    return im_sizes\n",
      "\n",
      "def show_image(im):\n",
      "    \"\"\" Display a grey scale version of the plankton image. \"\"\" \n",
      "    plt.imshow(im, cmap=cm.gray)\n",
      "    plt.show()\n",
      "\n",
      "def threshold_dilate_label_image(im):\n",
      "    im_thr = im.copy()\n",
      "    im_thr = np.where(im > np.mean(im), 0.0, 1.0).astype('uint8')\n",
      "    im_dil = morphology.dilation(im_thr, np.ones((5,5), dtype='uint8'))\n",
      "    im_lbld = measure.label(im_dil) * im_thr # each pixel labeled with int\n",
      "    return (im_thr, im_dil, im_lbld)\n",
      "\n",
      "def get_largest_region(im_thr, im_lbld):\n",
      "    region_props = measure.regionprops(im_lbld)\n",
      "    largest_region = None\n",
      "    for rp in region_props:\n",
      "        # check region is >= 50% nonzero\n",
      "        if sum(im_thr[im_lbld==rp.label]) * 1.0/rp.area < 0.50:\n",
      "            continue\n",
      "        if largest_region is None:\n",
      "            largest_region = rp\n",
      "        if largest_region.filled_area < rp.filled_area:\n",
      "            largest_region = rp\n",
      "    return largest_region\n",
      "\n",
      "def show_image5(im):\n",
      "    \"\"\" Display grey scale, threshold, dilated, and labeled\n",
      "    versions of the plankton image in fname. \"\"\" \n",
      "    im_thr, im_dil, im_lbld = threshold_dilate_label_image(im)\n",
      "    lrgst_reg = get_largest_region(im_thr, im_lbld)\n",
      "    im_lr = np.where(im_lbld==lrgst_reg.label, 0, 1)\n",
      "\n",
      "    f = plt.figure(figsize=(14,3))\n",
      "    sub1 = plt.subplot(1,5,1)\n",
      "    plt.imshow(im, cmap=cm.gray)\n",
      "    sub1.set_title(\"Original Image\")\n",
      "    sub2 = plt.subplot(1,5,2)\n",
      "    plt.imshow(im_thr, cmap=cm.gray_r)\n",
      "    sub2.set_title(\"Thresholded Image\")\n",
      "    sub3 = plt.subplot(1,5,3)\n",
      "    plt.imshow(im_dil, cmap=cm.gray_r)\n",
      "    sub3.set_title(\"Dilated Image\")\n",
      "    sub4 = plt.subplot(1,5,4)\n",
      "    plt.imshow(im_lbld)\n",
      "    sub4.set_title(\"Labeled Image\")\n",
      "    sub5 = plt.subplot(1,5,5)\n",
      "    plt.imshow(im_lr)\n",
      "    sub5.set_title(\"Largest Connected\")\n",
      "    plt.show()\n",
      "\n",
      "def get_minor_major_ratio(region):    \n",
      "    \"\"\" Return minor/major axis ratio from a region. \"\"\" \n",
      "    if (region is None) or (region.major_axis_length == 0.0):\n",
      "        return 0.0\n",
      "    else:\n",
      "        return region.minor_axis_length*1.0 / region.major_axis_length    \n",
      "\n",
      "\n",
      "def build_training_vectors(npx=32):\n",
      "    # check if rescaled training images exist\n",
      "    train_path = \"competition_data/train_{0}x{0}\".format(npx)\n",
      "    if not os.path.isdir(train_path):\n",
      "        print \"no rescaled training images for npx=\"+str(npx)\n",
      "        print \"train_path=\", train_path\n",
      "        sys.exit(1)\n",
      "\n",
      "    imageSize = npx*npx\n",
      "    num_rows = const.NTRAIN # one row for each image in the training dataset\n",
      "    num_features = npx*npx + 1 # all pixels + 1 for our ratio\n",
      "\n",
      "    # X is the feature vector with one row of features per image\n",
      "    # consisting of the pixel values and our metric\n",
      "    X = np.zeros((num_rows, num_features), dtype=float)\n",
      "    # y is the numeric class label \n",
      "    y = np.zeros(num_rows)\n",
      "\n",
      "    print \"Building training vectors\"\n",
      "    ifile = 0\n",
      "    report = [int((j+1)*num_rows/20.) for j in range(20)]\n",
      "    for icls, cls in enumerate(const.CLASS_NAMES):\n",
      "        cls_dir = os.path.join(train_path, cls)\n",
      "        for img_name in os.listdir(cls_dir):\n",
      "            fname = os.path.join(cls_dir, img_name)\n",
      "            im = read_image(fname)\n",
      "            im_thr, im_dil, im_lbld = threshold_dilate_label_image(im)\n",
      "            lrgst_reg = get_largest_region(im_thr, im_lbld)\n",
      "            axis_ratio = get_minor_major_ratio(lrgst_reg)\n",
      "\n",
      "            # Store the rescaled image pixels and the axis ratio\n",
      "            X[ifile, 0:imageSize] = np.reshape(im, (1, imageSize))\n",
      "            X[ifile, imageSize] = axis_ratio\n",
      "            \n",
      "            # Store the classlabel\n",
      "            y[ifile] = icls\n",
      "\n",
      "            ifile += 1\n",
      "            # report progress for each 5% done  \n",
      "            if ifile in report: \n",
      "                print np.ceil(ifile * 100.0 / num_rows), \"% done\"\n",
      "\n",
      "    return (X,y)\n",
      "\n",
      "def random_forest_classifier(X, y, n_estimators=100, cv=5):\n",
      "    print \"Creating random forest classifier\"\n",
      "    # n_estimators is the number of decision trees\n",
      "    # max_features also known as m_try is set to the default value of the \n",
      "    # square root of the number of features\n",
      "    clf = RF(n_estimators=n_estimators, n_jobs=2)\n",
      "\n",
      "    print \"Running cross_val_score\"\n",
      "    scores = cross_validation.cross_val_score(clf, X, y, cv=cv, n_jobs=2);\n",
      "\n",
      "    print \"Accuracy of all classes\"\n",
      "    print np.mean(scores)\n",
      "\n",
      "    print \"Running fit on 5 K-folds\"\n",
      "    kf = KFold(y, n_folds=5)\n",
      "    y_pred = y * 0\n",
      "    for train, test in kf:\n",
      "        X_train, X_test, y_train, y_test = \\\n",
      "            X[train,:], X[test,:], y[train], y[test]\n",
      "        clf = RF(n_estimators=100, n_jobs=3)\n",
      "        clf.fit(X_train, y_train)\n",
      "        y_pred[test] = clf.predict(X_test)\n",
      "    print classification_report(y, y_pred, target_names=const.CLASS_NAMES)\n",
      "\n",
      "def multiclass_log_loss(y_true, y_pred, eps=1e-15):\n",
      "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
      "    https://www.kaggle.com/wiki/MultiClassLogLoss\n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array, shape = [n_samples]\n",
      "            true class, intergers in [0, n_classes - 1)\n",
      "    y_pred : array, shape = [n_samples, n_classes]\n",
      "    Returns\n",
      "    -------\n",
      "    loss : float\n",
      "    \"\"\"\n",
      "    predictions = np.clip(y_pred, eps, 1 - eps)\n",
      "\n",
      "    # normalize row sums to 1\n",
      "    predictions /= predictions.sum(axis=1)[:, np.newaxis]\n",
      "\n",
      "    actual = np.zeros(y_pred.shape)\n",
      "    n_samples = actual.shape[0]\n",
      "    actual[np.arange(n_samples), y_true.astype(int)] = 1\n",
      "    vectsum = np.sum(actual * np.log(predictions))\n",
      "    loss = -1.0 / n_samples * vectsum\n",
      "    return loss\n",
      "\n",
      "def report_log_loss(X,y):\n",
      "    # Get the probability predictions for computing the log-loss function\n",
      "    kf = KFold(y, n_folds=5)\n",
      "    # prediction probabilities number of samples, by number of classes\n",
      "    y_pred = np.zeros((len(y),len(set(y))))\n",
      "    for train, test in kf:\n",
      "        X_train, X_test, y_train, y_test = \\\n",
      "            X[train,:], X[test,:], y[train], y[test]\n",
      "        clf = RF(n_estimators=100, n_jobs=2)\n",
      "        clf.fit(X_train, y_train)\n",
      "        y_pred[test] = clf.predict_proba(X_test)\n",
      "\n",
      "    print 'multiclass log loss=', multiclass_log_loss(y, y_pred)\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    X,y = build_training_vectors()\n",
      "    random_forest_classifier(X, y)\n",
      "    report_log_loss(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}