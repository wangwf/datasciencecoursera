{
 "metadata": {
  "name": "",
  "signature": "sha256:62eeebfa9a044515e39d5e3f7867ee515074307e921c0cc81655117bd57dabe9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Engineering with Graphlab Create"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note: This notebook uses GraphLab Create 0.9.**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Feature engineering is one of the **most important factors** in a successful machine learning project. With Graphlab Create's [SFrame](http://graphlab.com/products/create/docs/generated/graphlab.SFrame.html#graphlab.SFrame), we have at our disposal the tools to make this a painless and fun ride!\n",
      "\n",
      "Be sure to check out the [Introduction to Regression Analysis](intro-regression.html) notebook which provides an overview of how to use Graphlab Create to train regression and classification models, make predictions, and evaluate performance."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Overview "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook, we will go over:\n",
      "\n",
      "* [Creating regression models with categorical features](#Adding-Categorical-Features)\n",
      "* [Encoding features using python dictionaries & lists](#Dictionary-Features)\n",
      "* [Converting raw text data into useful features](#Text-Data:-Using-raw-review-data)\n",
      "\n",
      "**A preview of some fun facts revealed by our regression model:**\\*\n",
      "\n",
      "* Restaurants in Wittman, Arizona are not great but Good Year, Arizona has great food!\n",
      "* Yelp reviews with more **cool** votes from other users are more likely to be positive reviews.\n",
      "* Yelp reviews with more **funny** votes from other users are more likely to be negative.\n",
      "* Yelp reviews with more **useful** votes from other users are more likely to be negative.\n",
      "\n",
      "\\*Of course, these relationships are [correlations, not causations](http://en.wikipedia.org/wiki/Correlation_does_not_imply_causation).\n",
      "\n",
      "Let us start by importing Graphlab Create! "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import graphlab as gl\n",
      "gl.canvas.set_target('ipynb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Like the [Introduction to Regression Analysis](intro-regression.html) notebook, we   use data from the [Yelp Dataset Challenge](http://www.yelp.com/dataset_challenge) for this tutorial. The task is to **predict the 'star rating' of a restaurant for a given user.**\n",
      "\n",
      "The data consists of three tables containing info about 11,537 businesses, 8,282 checkin sets, 43,873 users, and 229,907 reviews. Details about each of the columns in the dataset are available on the [Yelp website](http://www.yelp.com/dataset_challenge). Please see the [Introduction to Regression Analysis](intro-regression.html) notebook for more details about the data preparation phase."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "business = gl.SFrame(\"business.csv\")\n",
      "user = gl.SFrame(\"user.csv\")\n",
      "review = gl.SFrame(\"review.csv\")\n",
      "#business = gl.SFrame('http://s3.amazonaws.com/GraphLab-Datasets/regression/business.csv')\n",
      "#user = gl.SFrame('http://s3.amazonaws.com/GraphLab-Datasets/regression/user.csv')\n",
      "#review = gl.SFrame('http://s3.amazonaws.com/GraphLab-Datasets/regression/review.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "business.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review_business_table = review.join(business, how='inner', on='business_id')\n",
      "review_business_table = review_business_table.rename({'stars.1': 'business_avg_stars', \n",
      "                              'type.1': 'business_type',\n",
      "                              'review_count': 'business_review_count'})\n",
      "\n",
      "user_business_review_table = review_business_table.join(user, how='inner', on='user_id')\n",
      "user_business_review_table = user_business_review_table.rename({'name.1': 'user_name', \n",
      "                                   'type.1': 'user_type', \n",
      "                                   'average_stars': 'user_avg_stars',\n",
      "                                   'review_count': 'user_review_count'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let us split the prepared data into training and testing sets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set, test_set = user_business_review_table.random_split(0.8, seed=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feature Engineering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GraphLab Create can handle features of the following types:\n",
      "\n",
      "* **Categorical variables**: strings such as \"Male\" or \"Female\"\n",
      "* **List features**: lists of numeric values such as [1.0, 2.0] \n",
      "* **Key-Value pair features**: dictionaries of the form {\"key1\": value1, \"key2\": value2}\n",
      "\n",
      "Graphlab Create's SFrame data structure is not currently optimized for holding more than a few hundred columns, but the list and dictionary types allow observations to have a much larger number of features in a single SFrame column. In this demo we will see examples of each of these complex feature types."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Adding Categorical Features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Categorical features usually require special attention in regression models. Often, this includes a messy pre-processing step to make the categorical features interpretable in the context of the model. With Graphlab Create, we can **add categorical features without any special pre-processing**. Throw in your features as strings and we will do all the munging for you! \n",
      "\n",
      "The variable **city** is a categorical variable in our dataset. We can use the SArray's handy [sketch_summary()](http://graphlab.com/products/create/docs/generated/graphlab.SArray.sketch_summary.html#graphlab.SArray.sketch_summary) function to get a quick glance at some useful statistics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set['city'].show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see there are about 60 unique strings for the **city** (the number of unique values is approximate in the GraphLab Sketch). The regression module in Graphlab Create uses **simple encoding** while training models using string features. Simple encoding compares each category to an arbitrary reference category (we choose the first category the data as the reference). [This article](http://www.ats.ucla.edu/stat/sas/webbooks/reg/chapter5/sasreg5.htm) provides more details about simple encoding for regression models."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In our [Introduction to Regression](intro-regression.html) notebook, we used the following numerical features:\n",
      "\n",
      "* Average rating of a given business\n",
      "* Average rating made by a user\n",
      "* Number of reviews made by a user\n",
      "* Number of reviews that concern a business\n",
      "\n",
      "Now we can easiliy add the **city** feature to the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = gl.linear_regression.create(train_set, target='stars', \n",
      "                                    features = ['user_avg_stars','business_avg_stars', \n",
      "                                                'user_review_count', 'business_review_count', \n",
      "                                                'city'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the **number of coefficients** and the **number of features** aren't the same. We add *dummy coefficients* to encode each category. The number of these dummy coefficients is equal to the total number of categories minus 1 (for the reference category). In this example, there are 60 unique cities, so 59 dummy coefficients.\n",
      "\n",
      "Let us see how well the model performed:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.evaluate(train_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.evaluate(test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "On average, our predicted rating was about 1 star away from the true rating but there were some corner cases which were off by almost 4 stars. Let's inspect the model to get more insight:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The coefficients for the categorical variables indicate the strength of the association between a category and the rating. In this example, we learn that restauraunts in Wittman, AZ and Florence, SC are likely to have worse ratings in comparison with Good Year, AZ and Grand Junction, CO, holding the other features constant.\n",
      "\n",
      "[Wikipedia](http://en.wikipedia.org/wiki/Grand_Junction,_Colorado) claims Grand Junction, CO was number six in [Outdoor Life's](http://en.wikipedia.org/wiki/Outdoor_Life) 2012 list of the 35 Best Hunting and Fishing Towns in the US. I am definitely planning my next vacation to Grand Junction. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Categorical Features at Scale"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Graphlab Create is built to scale. It can handle categorical variables with **millions** of categories, which we illustrate now by adding the **user-id** and **business-id** variables to our model.\n",
      "\n",
      "Notice that we omit the city as a feature because the business ID uniquely identifies the city. Removing this redundant information not only improves our ability to interpret the model, it makes the model [mathematically tractable](http://en.wikipedia.org/wiki/Multicollinearity). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = gl.linear_regression.create(train_set, target='stars', \n",
      "                                    features = ['user_id','business_id',\n",
      "                                                'user_avg_stars','business_avg_stars'],\n",
      "                                    solver_options={'max_iterations': 10})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We didn't have any trouble training the model with **over 50K terms in the model**. In fact, Graphlab Create can work with millions of features and billions of examples.\n",
      "\n",
      "Note, however, that the Solver status is now **TERMINATED: Iteration limit reached**. In the previous model, the solver reached the best possible solution in only one pass over the data, but in this case it reached the default stopping point of 10 iterations without finding the optimal solution. We can increase the iteration limit with the  [max_iterations](http://graphlab.com/products/create/docs/generated/graphlab.logistic_regression.create.html#graphlab.logistic_regression.create) option. With 100 iterations, the results do look slightly different."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = gl.linear_regression.create(train_set, target='stars', \n",
      "                                    features = ['user_id','business_id',\n",
      "                                                'user_avg_stars','business_avg_stars'],\n",
      "                                    solver_options={'max_iterations': 100})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dictionary and List Features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Graphlab Create can also handle dictionary features without any manual pre-processing. The Yelp reviews have information on the number of **funny**, **useful**, or **cool** votes received by each review. These tallies are stored in the dataset in the form of dictionaries, one per review."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set['votes'].head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use these dictionaries to create a linear regression model without manual data munging. Each key in a dictionary feature is treated as a separate term in the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = gl.linear_regression.create(train_set, target='stars', \n",
      "                                    features = ['user_id','business_id',\n",
      "                                                'user_avg_stars','votes', 'business_avg_stars','city'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our model tells us that, all else equal:\n",
      "\n",
      "* Reviews with more **cool** votes are more likely to be positive.\n",
      "* Reviews with more **funny** votes are more likely to be negative.\n",
      "* Reviews with more **useful** votes are more likely to be negative."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GraphLab Create can also handle list features without preprocessing. As an illustration, suppose the values of the **votes** dictionary variable had instead been stored in a list. We can use the SArray [apply](http://graphlab.com/products/create/docs/generated/graphlab.SArray.apply.html#graphlab.SArray.apply) function to simulate this situation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set['votes_list'] = train_set['votes'].apply(lambda x: x.values())\n",
      "train_set['votes_list'].head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As with the dictionary feature type, each entry of the list is treated as a separate term in the model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = gl.linear_regression.create(train_set, target='stars', \n",
      "                                    features = ['user_id','business_id',\n",
      "                                                'user_avg_stars','votes_list', 'business_avg_stars'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The only difference between the model trained using **votes** and **votes_list** is in the annotation of the returned coefficients. For the dictionary feature, we returned **votes_list[cool]** but now we return **votes_list[0]** (for example)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using Review Category Tags"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yelp reviews contain useful **tags** that describe each business. Unlike categorical variables, a business may have several tags. Confusingly, these tags are stored as lists of strings in the **categories** column in our datatset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set['categories'].head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Tag data takes a bit of pre-processing**. Let us define a function that converts each list of the form *[tag_1, tag_2, ..., tag_n]* to a dictionary of the form *{tag_1: 1, tag_2: 1,  ..., tag_n: 1}* where the keys are the tags and all values are 1 (indicating that the tag was present). We then apply this to each of the tag lists in our data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tags_to_dict = lambda tags: dict(zip(tags, [1 for tag in tags]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set['categories_dict'] = train_set.apply(lambda row: tags_to_dict(row['categories']))\n",
      "train_set['categories_dict'].head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we create a linear regression model with the **categories_dict** included in the feature list:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = gl.linear_regression.create(train_set, target='stars', \n",
      "                                    features = ['user_id','business_id', 'categories_dict',\n",
      "                                                'user_avg_stars','votes', 'business_avg_stars'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The model shows the tag **\"Food\"** has a slightly positive association with a business's rating, whereas **\"Restaurants\"** is slightly negatively associated. The influences are really small, so we will ingore them."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Text Data: Using Raw Review Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GraphLab Create's SArray has several very useful text processing capabilities. In this section, we apply these to the raw text of Yelp business reviews to improve our linear model's predictions.\n",
      "\n",
      "For this, we use the **[count_words](/products/create/docs/generated/graphlab.SArray.count_words.html)** SArray function converts a raw text string into a dictionary where the keys are the words and the values are the word counts. For example, the first review is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set['text'].head(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And the resulting word count dictionary:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set['negative_review_tags'] = train_set['text'].count_words()\n",
      "train_set['negative_review_tags'].head(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now use the **[dict_trim_by_keys](/products/create/docs/generated/graphlab.SArray.dict_trim_by_keys.html)** SArray function to trim the dictionary down to a set of words we are intereseted in.\n",
      "\n",
      "Our belief is that **negative** words suchs as *filthy* and *disgusting* are useful in predicting when a rating will be bad, so we construct a feature that captures these words. This belief is not justified by statistical or machine learning considerations, but this type of feature engineering often makes the difference between a **good** model and a **great** model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bad_review_words = ['hate','terrible', 'awful', 'spit', 'disgusting', 'filthy', 'tasteless', 'rude', \n",
      "                    'dirty', 'slow', 'poor', 'late', 'angry', 'flies', 'disappointed', 'disappointing', 'wait', \n",
      "                    'waiting', 'dreadful', 'appalling', 'horrific', 'horrifying', 'horrible', 'horrendous', 'atrocious', \n",
      "                    'abominable', 'deplorable', 'abhorrent', 'frightful', 'shocking', 'hideous', 'ghastly', 'grim', \n",
      "                    'dire', 'unspeakable', 'gruesome']\n",
      "train_set['negative_review_tags'] = train_set['negative_review_tags'].dict_trim_by_keys(bad_review_words, exclude=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set['negative_review_tags'].head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = gl.linear_regression.create(train_set, target='stars', \n",
      "                                    features = ['user_id', 'business_id', 'categories_dict', 'negative_review_tags', \n",
      "                                                'user_avg_stars', 'votes', 'business_avg_stars'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we hypothesized, the model tells us that the **negative** words contain important information in predicting star ratings! After building the tag dictionary and applying the same text transformations to the test dataset, we evaluate our model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_set['categories_dict'] = test_set.apply(lambda row: tags_to_dict(row['categories']))\n",
      "test_set['categories_dict'].head(5)\n",
      "\n",
      "test_set['negative_review_tags'] = test_set['text'].count_words()\n",
      "test_set['negative_review_tags'] = test_set['negative_review_tags'].dict_trim_by_keys(bad_review_words, exclude=False)\n",
      "model.evaluate(test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the tools in GraphLab Create, we can construct rich features for very powerful regression and classification models, all with very few lines of code."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}